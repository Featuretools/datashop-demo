{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.17'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "ft.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data has 75 columns:\n",
      "Index(['Sample Name', 'Transaction Id', 'Anon Student Id', 'Session Id',\n",
      "       'Time', 'Time Zone', 'Duration (sec)', 'Student Response Type',\n",
      "       'Student Response Subtype', 'Tutor Response Type',\n",
      "       'Tutor Response Subtype', 'Level (Unit)', 'Problem Name',\n",
      "       'Problem View', 'Problem Start Time', 'Step Name', 'Attempt At Step',\n",
      "       'Is Last Attempt', 'Outcome', 'Selection', 'Action', 'Input',\n",
      "       'Feedback Text', 'Feedback Classification', 'Help Level',\n",
      "       'Total Num Hints', 'KC (Geometry)', 'KC Category (Geometry)',\n",
      "       'KC (Textbook)', 'KC Category (Textbook)', 'KC (Single-KC)',\n",
      "       'KC Category (Single-KC)', 'KC (Unique-step)',\n",
      "       'KC Category (Unique-step)', 'KC (NewModel)', 'KC Category (NewModel)',\n",
      "       'KC (NNEWWW)', 'KC Category (NNEWWW)', 'KC (New)', 'KC Category (New)',\n",
      "       'KC (MyKC)', 'KC Category (MyKC)', 'KC (MJB-SQRECT-Merge)',\n",
      "       'KC Category (MJB-SQRECT-Merge)', 'KC (KRE_circle_area)',\n",
      "       'KC Category (KRE_circle_area)', 'KC (Textbook-test)',\n",
      "       'KC Category (Textbook-test)', 'KC (Khushboo)',\n",
      "       'KC Category (Khushboo)', 'KC (Zhulin_Textbook11_SquareRectMerge)',\n",
      "       'KC Category (Zhulin_Textbook11_SquareRectMerge)',\n",
      "       'KC (new KC model name)', 'KC Category (new KC model name)', 'School',\n",
      "       'Class', 'CF (Factor add-or-m)', 'CF (Factor backward)',\n",
      "       'CF (Factor base-formula-p)', 'CF (Factor base-or-height)',\n",
      "       'CF (Factor basic-shape)', 'CF (Factor cir-quad)',\n",
      "       'CF (Factor circle-formula)', 'CF (Factor circle-given)',\n",
      "       'CF (Factor circle-goal)', 'CF (Factor embedd3-tri-reg_prob_fix)',\n",
      "       'CF (Factor embeddedness)', 'CF (Factor figure-part)',\n",
      "       'CF (Factor figure-type)',\n",
      "       'CF (Factor non-standard-orientation-or-shape)',\n",
      "       'CF (Factor parallelogram)', 'CF (Factor parallelogram-type)',\n",
      "       'CF (Factor repeat)', 'CF (Factor required)',\n",
      "       'CF (Factor trapezoid-part)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/data.txt', '\\t')\n",
    "data.index = data['Transaction Id']\n",
    "data = data.drop(['Row'], axis=1)\n",
    "print(\"This data has {} columns:\".format(len(data.columns)))\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Creating a useful dataset structure\n",
    "Since we have so many categorical columns, it's worth taking a moment to think about how this data is structured. At the base level we have `transactions`, every event that is recorded in the data. The columns of those transactions have variables that can be grouped together. As an example, there are only 78 distinct `problem_steps` for the 6778 transactions we have. Associated to each such problem step, we have a variety of knowledge components (KC) and custom fields (CF) associated to that step.\n",
    "\n",
    "Because we can expect those columns to be consistently named, we can pull them all out at once using ordinary python list comprehensions and `normalize_entity` from featuretools. These steps will be consistent for any dataset of this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Geometry Dataset\n",
       "  Entities:\n",
       "    transactions (shape = [6778, 27])\n",
       "    problem_steps (shape = [78, 49])\n",
       "    problems (shape = [20, 1])\n",
       "    sessions (shape = [59, 2])\n",
       "    students (shape = [59, 1])\n",
       "    ...And 1 more\n",
       "  Relationships:\n",
       "    transactions.Step Name -> problem_steps.Step Name\n",
       "    problem_steps.Problem Name -> problems.Problem Name\n",
       "    transactions.Session Id -> sessions.Session Id\n",
       "    sessions.Anon Student Id -> students.Anon Student Id\n",
       "    transactions.Attempt At Step -> attempts.Attempt At Step"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#               students     problems\n",
    "#                 |         /\n",
    "#   attempts   sessions   problem steps\n",
    "#          \\     |       /\n",
    "#           transactions\n",
    "\n",
    "\n",
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "kc_and_cf_cols = [x for x in data.columns if (x.startswith('KC ') or x.startswith('CF '))]\n",
    "kc_and_cf_cols.append('Problem Name')\n",
    "data['Outcome'] = data['Outcome'].map({'INCORRECT': 0, 'CORRECT': 1})\n",
    "data['End Time'] = pd.to_datetime(data['Time'])+pd.to_timedelta(data['Duration (sec)'], 's')\n",
    "\n",
    "es = ft.EntitySet('Geometry Dataset')\n",
    "es.entity_from_dataframe(entity_id='transactions', \n",
    "                         index='Transaction Id', \n",
    "                         dataframe=data,\n",
    "                         variable_types={'Outcome': vtypes.Boolean},\n",
    "                         time_index='Time',\n",
    "                         secondary_time_index={'End Time': ['Outcome', 'Is Last Attempt', 'Duration (sec)']})\n",
    "\n",
    "es.normalize_entity(base_entity_id='transactions',\n",
    "                    new_entity_id='problem_steps',\n",
    "                    index='Step Name',\n",
    "                    additional_variables=kc_and_cf_cols,\n",
    "                    make_time_index=False)\n",
    "\n",
    "es.normalize_entity(base_entity_id='problem_steps',\n",
    "                    new_entity_id='problems',\n",
    "                    index='Problem Name',\n",
    "                    make_time_index=False)\n",
    "\n",
    "es.normalize_entity(base_entity_id='transactions',\n",
    "                    new_entity_id='sessions',\n",
    "                    index='Session Id',\n",
    "                    additional_variables=['Anon Student Id'],\n",
    "                    make_time_index=False)\n",
    "\n",
    "es.normalize_entity(base_entity_id='sessions',\n",
    "                    new_entity_id='students',\n",
    "                    index='Anon Student Id',\n",
    "                    make_time_index=False)\n",
    "\n",
    "es.normalize_entity(base_entity_id='transactions',\n",
    "                    new_entity_id='attempts',\n",
    "                    index='Attempt At Step',\n",
    "                    additional_variables=[],\n",
    "                    make_time_index=True)\n",
    "\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sample Name', 'Transaction Id', 'Session Id', 'Time', 'Time Zone',\n",
       "       'Duration (sec)', 'Student Response Type', 'Student Response Subtype',\n",
       "       'Tutor Response Type', 'Tutor Response Subtype', 'Level (Unit)',\n",
       "       'Problem View', 'Problem Start Time', 'Step Name', 'Attempt At Step',\n",
       "       'Is Last Attempt', 'Outcome', 'Selection', 'Action', 'Input',\n",
       "       'Feedback Text', 'Feedback Classification', 'Help Level',\n",
       "       'Total Num Hints', 'School', 'Class', 'End Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es['transactions'].df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Features\n",
    "We create a custom primitive: `Prob`, which calculates the likelihood that a boolean variable is false. It's worth noting that the opposite of this primitive is built in to Featuretools: `PercentTrue`. One of the many advantages in defining custom primitives is that we can define the name and input types as we would like. If you're interested in creating your own custom primitives for this dataset, copy and modify this code as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from featuretools.primitives import make_agg_primitive\n",
    "def probability(boolean):\n",
    "    numtrue = len([x for x in boolean if x==1])\n",
    "    return 1 - numtrue/len(boolean)\n",
    "\n",
    "Prob = make_agg_primitive(probability,\n",
    "                          input_types=[vtypes.Boolean],\n",
    "                          name='failure_rate',\n",
    "                          description='Calculates likelihood a boolean is false over a region',\n",
    "                          return_type=vtypes.Numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate a feature matrix on the `transactions` entity to try to predict the outcome of a given transaction. It's at this step that our previous setup pays off: we can automatically calculate features as if at a given point in time using Deep Feature Synthesis. Furthermore, we can guarentee that future values for `Outcome` won't be used for any calculations because we set the time index of that value to be after the cutoff time.\n",
    "\n",
    "Lastly, we can automatically apply `Prob` while grouping by any of the entities we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features: 143it [00:00, 6821.87it/s]\n",
      "Progress: 100%|██████████| 120/120 [01:33<00:00,  1.29cutoff time/s]\n",
      "Created 74 features\n"
     ]
    }
   ],
   "source": [
    "# Automatically generate features on collected data\n",
    "from featuretools.primitives import Sum, Mean, Median, Count, Hour \n",
    "cutoff_times = data[['Transaction Id', 'Time', 'Outcome']][500:]\n",
    "cutoff_times['Time'] = pd.to_datetime(cutoff_times['Time'])\n",
    "fm, features = ft.dfs(entityset=es, \n",
    "                      target_entity='transactions',\n",
    "                      agg_primitives=[Prob],\n",
    "                      trans_primitives=[],\n",
    "                      seed_features=[],\n",
    "                      max_depth=3,\n",
    "                      approximate='1m',\n",
    "                      cutoff_time=cutoff_times,\n",
    "                      verbose=True)\n",
    "print('Created {} features'.format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: problem_steps.CF (Factor trapezoid-part)>,\n",
       " <Feature: problem_steps.Problem Name>,\n",
       " <Feature: sessions.Anon Student Id>,\n",
       " <Feature: problem_steps.FAILURE_RATE(transactions.Outcome)>,\n",
       " <Feature: sessions.FAILURE_RATE(transactions.Outcome)>,\n",
       " <Feature: attempts.FAILURE_RATE(transactions.Outcome)>,\n",
       " <Feature: problem_steps.problems.FAILURE_RATE(transactions.Outcome)>,\n",
       " <Feature: sessions.students.FAILURE_RATE(transactions.Outcome)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[-8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse a couple of features. The feature `problem_steps.FAILURE_RATE(transactions.Outcome)` is exactly the percent of students who did not succeed on a given `problem_step` as calculated at a given time. Similarly, the `attempts.FAILURE_RATE(transactions.Outcome)` is the failure rate as grouped by the problem attempt (i.e. more students miss the questions on an earlier attempts than later ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.selection import remove_low_information_features\n",
    "fm_enc, _ = ft.encode_features(fm, features)\n",
    "fm_enc = fm_enc.fillna(0)\n",
    "fm_enc = remove_low_information_features(fm_enc)\n",
    "labels = fm.pop('Outcome')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on time split 0 is 0.6\n",
      "[(0.1337026297426933, 'sessions.students.FAILURE_RATE(transactions.Outcome)'), (0.10700496004502816, 'sessions.FAILURE_RATE(transactions.Outcome)'), (0.10637038180553655, 'attempts.FAILURE_RATE(transactions.Outcome)'), (0.0837125374049934, 'problem_steps.FAILURE_RATE(transactions.Outcome)'), (0.07826273247899355, 'problem_steps.problems.FAILURE_RATE(transactions.Outcome)')]\n",
      "AUC score on time split 1 is 0.6\n",
      "[(0.15051363545733915, 'sessions.students.FAILURE_RATE(transactions.Outcome)'), (0.15014320148753196, 'sessions.FAILURE_RATE(transactions.Outcome)'), (0.12471825254376057, 'attempts.FAILURE_RATE(transactions.Outcome)'), (0.08880605139516665, 'problem_steps.FAILURE_RATE(transactions.Outcome)'), (0.08468644597671429, 'problem_steps.problems.FAILURE_RATE(transactions.Outcome)')]\n",
      "AUC score on time split 2 is 0.61\n",
      "[(0.14266583800988802, 'sessions.FAILURE_RATE(transactions.Outcome)'), (0.13988039617382023, 'sessions.students.FAILURE_RATE(transactions.Outcome)'), (0.12754424284183105, 'attempts.FAILURE_RATE(transactions.Outcome)'), (0.10609469370353261, 'problem_steps.FAILURE_RATE(transactions.Outcome)'), (0.09734579691379483, 'problem_steps.problems.FAILURE_RATE(transactions.Outcome)')]\n",
      "AUC score on time split 3 is 0.62\n",
      "[(0.1432736035127284, 'sessions.students.FAILURE_RATE(transactions.Outcome)'), (0.13404986923073797, 'sessions.FAILURE_RATE(transactions.Outcome)'), (0.1337061534193814, 'attempts.FAILURE_RATE(transactions.Outcome)'), (0.11172891153651532, 'problem_steps.FAILURE_RATE(transactions.Outcome)'), (0.09829417843426826, 'problem_steps.problems.FAILURE_RATE(transactions.Outcome)')]\n",
      "AUC score on time split 4 is 0.57\n",
      "[(0.147178670701252, 'sessions.students.FAILURE_RATE(transactions.Outcome)'), (0.1378603289400216, 'attempts.FAILURE_RATE(transactions.Outcome)'), (0.13366212673518824, 'sessions.FAILURE_RATE(transactions.Outcome)'), (0.11959748536414427, 'problem_steps.FAILURE_RATE(transactions.Outcome)'), (0.09351576902800944, 'problem_steps.problems.FAILURE_RATE(transactions.Outcome)')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "splitter = TimeSeriesSplit(n_splits=5, max_train_size=None)\n",
    "i=0\n",
    "for train_index, test_index in splitter.split(fm):\n",
    "    clf = RandomForestClassifier()\n",
    "    X_train, X_test = fm_enc.iloc[train_index], fm_enc.iloc[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    score = round(roc_auc_score(preds, y_test), 2)\n",
    "    print(\"AUC score on time split {} is {}\".format(i, score))\n",
    "    feature_imps = [(imp, fm_enc.columns[i]) for i, imp in enumerate(clf.feature_importances_)]\n",
    "    feature_imps.sort()\n",
    "    feature_imps.reverse()\n",
    "    print(feature_imps[0:5])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
