{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "ft.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This is a notebook which shows how we can create an EntitySet from a dataset with the DataShop structure. The content of this notebook, the function `datashop_to_entityset`, is also in [utilities](utilities.py) so that it can be loaded as a package in the [demo](Demo%20-%20DataShop.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools.variable_types as vtypes\n",
    "def datashop_to_entityset(filename):\n",
    "    # Make an EntitySet called Dataset with the following structure\n",
    "    #\n",
    "    # schools       students     problems\n",
    "    #        \\        |         /\n",
    "    #   classes   sessions   problem steps\n",
    "    #          \\     |       /\n",
    "    #           transactions  -- attempts\n",
    "    #\n",
    "\n",
    "    # Convert the csv into a dataframe using pandas\n",
    "    data = pd.read_csv(filename, '\\t')\n",
    "\n",
    "    # Make the Transaction Id the index column of the dataframe and clean other columns\n",
    "    data.index = data['Transaction Id']\n",
    "    data = data.drop(['Row'], axis=1)\n",
    "    data['Outcome'] = data['Outcome'].map({'INCORRECT': 0, 'CORRECT': 1})\n",
    "\n",
    "    # Make a new 'End Time' column which is start_time + duration\n",
    "    # This is /super useful/ because you shouldn't be using outcome data at\n",
    "    # any point before the student has attempted the problem.\n",
    "    data['End Time'] = pd.to_datetime(data['Time']) + pd.to_timedelta(pd.to_numeric(data['Duration (sec)']), 's')\n",
    "\n",
    "    # Make a list of all the KC and CF columns present\n",
    "    kc_and_cf_cols = [x for x in data.columns if (x.startswith('KC ') or x.startswith('CF '))]\n",
    "\n",
    "    # Now we start making an entityset. We make 'End Time' a time index for 'Outcome'\n",
    "    # even though our primary time index for a row is 'Time' preventing label leakage.\n",
    "    es = ft.EntitySet('Dataset')\n",
    "    es.entity_from_dataframe(entity_id='transactions',\n",
    "                             index='Transaction Id',\n",
    "                             dataframe=data,\n",
    "                             variable_types={'Outcome': vtypes.Boolean},\n",
    "                             time_index='Time',\n",
    "                             secondary_time_index={'End Time': ['Outcome', 'Is Last Attempt', 'Duration (sec)']})\n",
    "\n",
    "    # Every transaction has a `problem_step` which is associated to a problem\n",
    "    es.normalize_entity(base_entity_id='transactions',\n",
    "                        new_entity_id='problem_steps',\n",
    "                        index='Step Name',\n",
    "                        additional_variables=['Problem Name'],\n",
    "                        make_time_index=False)\n",
    "\n",
    "    es.normalize_entity(base_entity_id='problem_steps',\n",
    "                        new_entity_id='problems',\n",
    "                        index='Problem Name',\n",
    "                        make_time_index=False)\n",
    "\n",
    "    # Every transaction has a `session` associated to a student\n",
    "    es.normalize_entity(base_entity_id='transactions',\n",
    "                        new_entity_id='sessions',\n",
    "                        index='Session Id',\n",
    "                        additional_variables=['Anon Student Id'],\n",
    "                        make_time_index=True)\n",
    "\n",
    "    es.normalize_entity(base_entity_id='sessions',\n",
    "                        new_entity_id='students',\n",
    "                        index='Anon Student Id',\n",
    "                        make_time_index=True)\n",
    "\n",
    "    # Every transaction has a `class` associated to a school\n",
    "    es.normalize_entity(base_entity_id='transactions',\n",
    "                        new_entity_id='classes',\n",
    "                        index='Class',\n",
    "                        additional_variables=['School'],\n",
    "                        make_time_index=False)\n",
    "\n",
    "    es.normalize_entity(base_entity_id='classes',\n",
    "                        new_entity_id='schools',\n",
    "                        index='School',\n",
    "                        make_time_index=False)\n",
    "\n",
    "    # And because we might be interested in creating features grouped\n",
    "    # by attempts we normalize by those as well.\n",
    "    es.normalize_entity(base_entity_id='transactions',\n",
    "                        new_entity_id='attempts',\n",
    "                        index='Attempt At Step',\n",
    "                        additional_variables=[],\n",
    "                        make_time_index=False)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Dataset\n",
       "  Entities:\n",
       "    transactions [Rows: 6778, Columns: 179]\n",
       "    problem_steps [Rows: 78, Columns: 2]\n",
       "    problems [Rows: 20, Columns: 1]\n",
       "    sessions [Rows: 59, Columns: 3]\n",
       "    students [Rows: 59, Columns: 2]\n",
       "    classes [Rows: 1, Columns: 2]\n",
       "    schools [Rows: 1, Columns: 1]\n",
       "    attempts [Rows: 9, Columns: 1]\n",
       "  Relationships:\n",
       "    transactions.Step Name -> problem_steps.Step Name\n",
       "    problem_steps.Problem Name -> problems.Problem Name\n",
       "    transactions.Session Id -> sessions.Session Id\n",
       "    sessions.Anon Student Id -> students.Anon Student Id\n",
       "    transactions.Class -> classes.Class\n",
       "    classes.School -> schools.School\n",
       "    transactions.Attempt At Step -> attempts.Attempt At Step"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/ds76_tx_All_Data_74_2018_0912_070949.txt'\n",
    "es = datashop_to_entityset(filename)\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In total we have made 8 entities. At the base is `transactions` and then we have the following one-to-many relationships which have a one-to-many with `transactions`:\n",
    "1. `problems` -> `problem_steps` -> `transactions`  \n",
    "2. `students` -> `sessions`  -> `transactions`\n",
    "3. `schools` -> `classes` -> `transactions`\n",
    "4. `attempts` -> `transactions`\n",
    "\n",
    "Our base entity also has a time index `Time` and a secondary time index `End Time` for columns which can only be known when the event is over. This allows us to use `Outcome` in our feature matrix, since it will only be used for later events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
