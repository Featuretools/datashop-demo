{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.17'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "ft.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This is a notebook which shows how we can create an EntitySet from a dataset with the LearnLab structure. The content of this notebook, the function `learnlab_to_entityset`, is also in [utilities](utilities.py) so that it can be loaded as a package in the [demo](Demo%20-%20LearnLab.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "def learnlab_to_entityset(data):\n",
    "    # Make an EntitySet called Dataset with the following structure\n",
    "    #\n",
    "    # schools       students     problems\n",
    "    #        \\        |         /\n",
    "    #   classes   sessions   problem steps\n",
    "    #          \\     |       /\n",
    "    #           transactions  -- attempts\n",
    "    #\n",
    "    \n",
    "    # Set the Transaction Id as the index column for the whole table\n",
    "    # and clean up other columns.\n",
    "    data.index = data['Transaction Id']\n",
    "    data = data.drop(['Row'], axis=1)\n",
    "    data['Outcome'] = data['Outcome'].map({'INCORRECT': 0, 'CORRECT': 1})\n",
    "    \n",
    "    # Make a new 'End Time' column which is start_time + duration\n",
    "    # This is /super useful/ because you shouldn't be using the outcome data at \n",
    "    # any point before the End Time since it's not known.\n",
    "    data['End Time'] = pd.to_datetime(data['Time']) + pd.to_timedelta(pd.to_numeric(data['Duration (sec)']), 's')\n",
    "\n",
    "\n",
    "    # Make a list of all KC and CF columns present\n",
    "    kc_and_cf_cols = [x for x in data.columns if (x.startswith('KC ') or x.startswith('CF '))]\n",
    "    kc_and_cf_cols.append('Problem Name')\n",
    "    \n",
    "    # Now we start making an entityset. We make 'End Time' a time index for 'Outcome',\n",
    "    # even though our primary time index for a row is 'Time'\n",
    "    es = ft.EntitySet('Dataset')\n",
    "    es.entity_from_dataframe(entity_id='transactions', \n",
    "                             index='Transaction Id', \n",
    "                             dataframe=data,\n",
    "                             variable_types={'Outcome': vtypes.Boolean},\n",
    "                             time_index='Time',\n",
    "                             secondary_time_index={'End Time': ['Outcome', 'Is Last Attempt', 'Duration (sec)']})\n",
    "    \n",
    "    # Every transaction has a 'problem step', which is associated to a 'problem'\n",
    "    es.normalize_entity(base_entity_id='transactions',\n",
    "                        new_entity_id='problem_steps',\n",
    "                        index='Step Name',\n",
    "                        additional_variables=kc_and_cf_cols,\n",
    "                        make_time_index=False)\n",
    "\n",
    "    es.normalize_entity(base_entity_id='problem_steps',\n",
    "                        new_entity_id='problems',\n",
    "                        index='Problem Name',\n",
    "                        make_time_index=False)\n",
    "    \n",
    "    \n",
    "    # Every transaction has a 'session' which is associated to a 'student'\n",
    "    es.normalize_entity(base_entity_id='transactions',\n",
    "                        new_entity_id='sessions',\n",
    "                        index='Session Id',\n",
    "                        additional_variables=['Anon Student Id'],\n",
    "                        make_time_index=True)\n",
    "\n",
    "    es.normalize_entity(base_entity_id='sessions',\n",
    "                        new_entity_id='students',\n",
    "                        index='Anon Student Id',\n",
    "                        make_time_index=True)\n",
    "    \n",
    "    # Every transaction has a 'class' which is associated to a 'school'\n",
    "    es.normalize_entity(base_entity_id='transactions',\n",
    "                        new_entity_id='classes',\n",
    "                        index='Class',\n",
    "                        additional_variables=['School'],\n",
    "                        make_time_index=False)\n",
    "    \n",
    "    es.normalize_entity(base_entity_id='classes',\n",
    "                        new_entity_id='schools',\n",
    "                        index='School',\n",
    "                        make_time_index=False)\n",
    "\n",
    "    # And we might be interested in grouping by attempts, \n",
    "    # so make a table of those as well\n",
    "    es.normalize_entity(base_entity_id='transactions',\n",
    "                        new_entity_id='attempts',\n",
    "                        index='Attempt At Step',\n",
    "                        additional_variables=[],\n",
    "                        make_time_index=False)\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Dataset\n",
       "  Entities:\n",
       "    transactions (shape = [6778, 26])\n",
       "    problem_steps (shape = [78, 49])\n",
       "    problems (shape = [20, 1])\n",
       "    sessions (shape = [59, 3])\n",
       "    students (shape = [59, 2])\n",
       "    ...And 3 more\n",
       "  Relationships:\n",
       "    transactions.Step Name -> problem_steps.Step Name\n",
       "    problem_steps.Problem Name -> problems.Problem Name\n",
       "    transactions.Session Id -> sessions.Session Id\n",
       "    sessions.Anon Student Id -> students.Anon Student Id\n",
       "    transactions.Class -> classes.Class\n",
       "    ...and 2 more"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/ds2174_tx_All_Data_3991_2017_1128_123859.txt', '\\t')\n",
    "data.columns\n",
    "es = learnlab_to_entityset(data)\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In total we have made 8 entities. At the base is `transactions` and then we have the following one-to-many relationships which have a one-to-many with `transactions`:\n",
    "1. `problems` -> `problem_steps` -> `transactions`  \n",
    "2. `students` -> `sessions`  -> `transactions`\n",
    "3. `schools` -> `classes` -> `transactions`\n",
    "4. `attempts` -> `transactions`\n",
    "\n",
    "Our base entity also has a time index `Time` and a secondary time index `End Time` for columns which can only be known when the event is over. This allows us to use `Outcome` in our feature matrix, since it will only be used for later events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
